---
version: "3"

tasks:
  # ── Top-level composite tasks ──────────────────────────────
  default:
    desc: Build all runners
    cmds:
      - task: build

  build:
    desc: Build all runners and server
    aliases: [b]
    cmds:
      - task: build:go
      - task: build:rs
      - task: build:zig
      - task: build:server

  test:
    desc: Run conformance tests for all runners
    aliases: [t]
    cmds:
      - task: test:go
      - task: test:rs
      - task: test:zig

  do:
    desc: Pre-commit checks
    cmds:
      - task: build
      - task: test

  signoff:
    desc: Full validation for CI
    cmds:
      - task: do
      - gh signoff

  # ── Build server ────────────────────────────────────────────
  build:server:
    desc: Build conformance server
    aliases: [bs]
    dir: server
    cmds:
      - go build -o conformance-server .

  # ── Build per-language ─────────────────────────────────────
  build:go:
    desc: Build Go runner
    aliases: [bg]
    dir: runners/go
    cmds:
      - go build -o runner-go .

  build:rs:
    desc: Build Rust runner
    aliases: [brs]
    dir: runners/rs
    cmds:
      - cargo build --release

  build:zig:
    desc: Build Zig runner
    aliases: [bz]
    dir: runners/zig
    cmds:
      - ../../bin/zig build -Doptimize=ReleaseSafe

  # ── Test per-language ──────────────────────────────────────
  test:go:
    desc: Run conformance tests with Go runner
    aliases: [tg]
    deps: [build:go]
    cmds:
      - task: conformance
        vars:
          RUNNER: runners/go/runner-go
          LANG: go

  test:rs:
    desc: Run conformance tests with Rust runner
    aliases: [trs]
    deps: [build:rs]
    cmds:
      - task: conformance
        vars:
          RUNNER: runners/rs/target/release/runner-rs
          LANG: rs

  test:zig:
    desc: Run conformance tests with Zig runner
    aliases: [tz]
    deps: [build:zig]
    cmds:
      - task: conformance
        vars:
          RUNNER: runners/zig/zig-out/bin/runner-zig
          LANG: zig

  # ── Core conformance logic ─────────────────────────────────
  conformance:
    desc: Run all test cases against a single runner
    internal: true
    cmds:
      - |
        set +e
        # Normalize proto JSON: some encoders emit uint64 as strings, others as numbers
        normalize='def enums: {"SPAN_KIND_INTERNAL":1,"SPAN_KIND_SERVER":2,"SPAN_KIND_CLIENT":3,"SPAN_KIND_PRODUCER":4,"SPAN_KIND_CONSUMER":5,"STATUS_CODE_OK":1,"STATUS_CODE_ERROR":2,"AGGREGATION_TEMPORALITY_DELTA":1,"AGGREGATION_TEMPORALITY_CUMULATIVE":2,"SEVERITY_NUMBER_TRACE":1,"SEVERITY_NUMBER_TRACE2":2,"SEVERITY_NUMBER_TRACE3":3,"SEVERITY_NUMBER_TRACE4":4,"SEVERITY_NUMBER_DEBUG":5,"SEVERITY_NUMBER_DEBUG2":6,"SEVERITY_NUMBER_DEBUG3":7,"SEVERITY_NUMBER_DEBUG4":8,"SEVERITY_NUMBER_INFO":9,"SEVERITY_NUMBER_INFO2":10,"SEVERITY_NUMBER_INFO3":11,"SEVERITY_NUMBER_INFO4":12,"SEVERITY_NUMBER_WARN":13,"SEVERITY_NUMBER_WARN2":14,"SEVERITY_NUMBER_WARN3":15,"SEVERITY_NUMBER_WARN4":16,"SEVERITY_NUMBER_ERROR":17,"SEVERITY_NUMBER_ERROR2":18,"SEVERITY_NUMBER_ERROR3":19,"SEVERITY_NUMBER_ERROR4":20,"SEVERITY_NUMBER_FATAL":21,"SEVERITY_NUMBER_FATAL2":22,"SEVERITY_NUMBER_FATAL3":23,"SEVERITY_NUMBER_FATAL4":24}; walk(if type == "object" then with_entries(select(.value != null and .value != [] and .value != "" and .value != 0 and .value != {} and .value != false and (.value | IN("SEVERITY_NUMBER_UNSPECIFIED","STATUS_CODE_UNSET","SPAN_KIND_UNSPECIFIED","AGGREGATION_TEMPORALITY_UNSPECIFIED") | not)) | if .value | type == "string" then .value = (enums[.value] // .value) else . end) elif type == "string" and test("^[0-9]+$") then tonumber elif type == "number" and (. | floor) == . then (. | floor) else . end)'
        # Merge stats: sum hits/misses per policy_id across multiple stats files
        merge_stats='[.[].policies[]] | group_by(.policy_id) | map({policy_id: .[0].policy_id, hits: (map(.hits) | add), misses: (map(.misses // 0) | add)}) | map(if .misses == 0 then del(.misses) else . end) | sort_by(.policy_id) | {policies: .}'
        # Detect signal type from JSON content
        detect_signal='if .resourceLogs then "log" elif .resourceMetrics then "metric" elif .resourceSpans then "trace" else "unknown" end'

        TC_FILTER="{{.TC}}"
        PASS=0; FAIL=0
        for tc in testcases/*/; do
          name=$(basename "$tc")

          # If TC filter is set, only run that test case
          if [ -n "$TC_FILTER" ] && [ "$name" != "$TC_FILTER" ]; then
            continue
          fi

          if [ -f "$tc/input.json" ]; then
            # ── Simple mode: single input/output ──
            case "$name" in
              logs_*)    signal=log ;;
              metrics_*) signal=metric ;;
              traces_*)  signal=trace ;;
              *)         echo "  SKIP  $name (unknown signal)"; continue ;;
            esac
            ./{{.RUNNER}} \
              --policies "$tc/policies.json" \
              --input "$tc/input.json" \
              --output "$tc/output_{{.LANG}}.json" \
              --stats "$tc/stats_{{.LANG}}.json" \
              --signal "$signal"
            out_ok=true; stats_ok=true
            if ! diff <(jq -S "$normalize" "$tc/expected.json") \
                      <(jq -S "$normalize" "$tc/output_{{.LANG}}.json") > /dev/null 2>&1; then
              out_ok=false
            fi
            if ! diff <(jq -S . "$tc/expected_stats.json") \
                      <(jq -S . "$tc/stats_{{.LANG}}.json") > /dev/null 2>&1; then
              stats_ok=false
            fi
          else
            # ── Compound mode: multiple input_N/expected_N pairs ──
            out_ok=true; stats_ok=true
            STATS_FILES=""
            for input_file in $(ls "$tc"/input_*.json 2>/dev/null | sort -t_ -k2 -n); do
              n=$(basename "$input_file" | sed 's/input_\(.*\)\.json/\1/')
              expected_file="$tc/expected_${n}.json"
              output_file="$tc/output_${n}_{{.LANG}}.json"
              stats_file="$tc/stats_${n}_{{.LANG}}.json"
              signal=$(jq -r "$detect_signal" "$input_file")
              if [ "$signal" = "unknown" ]; then
                echo "  SKIP  $name/input_${n}.json (unknown signal)"; continue
              fi
              ./{{.RUNNER}} \
                --policies "$tc/policies.json" \
                --input "$input_file" \
                --output "$output_file" \
                --stats "$stats_file" \
                --signal "$signal"
              if [ -f "$expected_file" ]; then
                if ! diff <(jq -S "$normalize" "$expected_file") \
                          <(jq -S "$normalize" "$output_file") > /dev/null 2>&1; then
                  out_ok=false
                fi
              fi
              STATS_FILES="$STATS_FILES $stats_file"
            done
            # Merge all per-batch stats and compare once
            if [ -n "$STATS_FILES" ]; then
              jq -s "$merge_stats" $STATS_FILES > "$tc/stats_{{.LANG}}.json"
              if ! diff <(jq -S . "$tc/expected_stats.json") \
                        <(jq -S . "$tc/stats_{{.LANG}}.json") > /dev/null 2>&1; then
                stats_ok=false
              fi
            fi
          fi

          if $out_ok && $stats_ok; then
            echo "  PASS  $name"
            PASS=$((PASS + 1))
          else
            echo "  FAIL  $name"
            if ! $out_ok; then
              if [ -f "$tc/input.json" ]; then
                echo "    output diff:"
                diff <(jq -S "$normalize" "$tc/expected.json") \
                     <(jq -S "$normalize" "$tc/output_{{.LANG}}.json") || true
              else
                for input_file in $(ls "$tc"/input_*.json 2>/dev/null | sort -t_ -k2 -n); do
                  n=$(basename "$input_file" | sed 's/input_\(.*\)\.json/\1/')
                  expected_file="$tc/expected_${n}.json"
                  output_file="$tc/output_${n}_{{.LANG}}.json"
                  if [ -f "$expected_file" ] && ! diff <(jq -S "$normalize" "$expected_file") \
                        <(jq -S "$normalize" "$output_file") > /dev/null 2>&1; then
                    echo "    output diff (batch $n):"
                    diff <(jq -S "$normalize" "$expected_file") \
                         <(jq -S "$normalize" "$output_file") || true
                  fi
                done
              fi
            fi
            if ! $stats_ok; then
              echo "    stats diff:"
              diff <(jq -S . "$tc/expected_stats.json") \
                   <(jq -S . "$tc/stats_{{.LANG}}.json") || true
            fi
            FAIL=$((FAIL + 1))
          fi
        done
        echo ""
        echo "{{.LANG}}: $PASS passed, $FAIL failed"
        [ "$FAIL" -eq 0 ]

  # ── HTTP provider tests ─────────────────────────────────────
  test:http:go:
    desc: Run HTTP provider conformance tests for Go runner
    deps: [build:server, build:go]
    cmds:
      - task: conformance:http
        vars:
          { RUNNER: runners/go/runner-go, LANG: go, PROVIDER_FLAG: "--server" }

  test:http:rs:
    desc: Run HTTP provider conformance tests for Rust runner
    deps: [build:server, build:rs]
    cmds:
      - task: conformance:http
        vars:
          {
            RUNNER: runners/rs/target/release/runner-rs,
            LANG: rs,
            PROVIDER_FLAG: "--server",
          }

  test:http:zig:
    desc: Run HTTP provider conformance tests for Zig runner
    deps: [build:server, build:zig]
    cmds:
      - task: conformance:http
        vars:
          {
            RUNNER: runners/zig/zig-out/bin/runner-zig,
            LANG: zig,
            PROVIDER_FLAG: "--server",
          }

  test:http:
    desc: Run HTTP provider conformance tests for all runners
    aliases: [th]
    deps: [build:server, build:go, build:rs, build:zig]
    cmds:
      - task: test:http:go
      - task: test:http:rs
      - task: test:http:zig

  test:grpc:go:
    desc: Run gRPC provider conformance tests for Go runner
    deps: [build:server, build:go]
    cmds:
      - task: conformance:http
        vars:
          { RUNNER: runners/go/runner-go, LANG: go, PROVIDER_FLAG: "--grpc" }

  test:grpc:rs:
    desc: Run gRPC provider conformance tests for Rust runner
    deps: [build:server, build:rs]
    cmds:
      - task: conformance:http
        vars:
          {
            RUNNER: runners/rs/target/release/runner-rs,
            LANG: rs,
            PROVIDER_FLAG: "--grpc",
          }

  test:grpc:
    desc: Run gRPC provider conformance tests for all runners
    aliases: [tgrpc]
    deps: [build:server, build:go, build:rs]
    cmds:
      - task: test:grpc:go
      - task: test:grpc:rs

  conformance:http:
    desc: Run HTTP/gRPC provider test cases against a single runner
    internal: true
    cmds:
      - |
        set +e
        normalize='def enums: {"SPAN_KIND_INTERNAL":1,"SPAN_KIND_SERVER":2,"SPAN_KIND_CLIENT":3,"SPAN_KIND_PRODUCER":4,"SPAN_KIND_CONSUMER":5,"STATUS_CODE_OK":1,"STATUS_CODE_ERROR":2,"AGGREGATION_TEMPORALITY_DELTA":1,"AGGREGATION_TEMPORALITY_CUMULATIVE":2,"SEVERITY_NUMBER_TRACE":1,"SEVERITY_NUMBER_TRACE2":2,"SEVERITY_NUMBER_TRACE3":3,"SEVERITY_NUMBER_TRACE4":4,"SEVERITY_NUMBER_DEBUG":5,"SEVERITY_NUMBER_DEBUG2":6,"SEVERITY_NUMBER_DEBUG3":7,"SEVERITY_NUMBER_DEBUG4":8,"SEVERITY_NUMBER_INFO":9,"SEVERITY_NUMBER_INFO2":10,"SEVERITY_NUMBER_INFO3":11,"SEVERITY_NUMBER_INFO4":12,"SEVERITY_NUMBER_WARN":13,"SEVERITY_NUMBER_WARN2":14,"SEVERITY_NUMBER_WARN3":15,"SEVERITY_NUMBER_WARN4":16,"SEVERITY_NUMBER_ERROR":17,"SEVERITY_NUMBER_ERROR2":18,"SEVERITY_NUMBER_ERROR3":19,"SEVERITY_NUMBER_ERROR4":20,"SEVERITY_NUMBER_FATAL":21,"SEVERITY_NUMBER_FATAL2":22,"SEVERITY_NUMBER_FATAL3":23,"SEVERITY_NUMBER_FATAL4":24}; walk(if type == "object" then with_entries(select(.value != null and .value != [] and .value != "" and .value != 0 and .value != {} and .value != false and (.value | IN("SEVERITY_NUMBER_UNSPECIFIED","STATUS_CODE_UNSET","SPAN_KIND_UNSPECIFIED","AGGREGATION_TEMPORALITY_UNSPECIFIED") | not)) | if .value | type == "string" then .value = (enums[.value] // .value) else . end) elif type == "string" and test("^[0-9]+$") then tonumber elif type == "number" and (. | floor) == . then (. | floor) else . end)'
        detect_signal='if .resourceLogs then "log" elif .resourceMetrics then "metric" elif .resourceSpans then "trace" else "unknown" end'
        # Normalize expected stats for HTTP comparison: server only reports {policy_id, hits} for policies with hits > 0
        normalize_http_stats='{policies: [.policies[] | del(.misses) | select(.hits > 0)] | sort_by(.policy_id)}'
        PASS=0; FAIL=0; ERRORS=0
        for tc in testcases/*/; do
          name=$(basename "$tc")

          # Start conformance server; read port lines from stdout via pipe (no sleeps)
          PORT_FIFO=$(mktemp -u)
          mkfifo "$PORT_FIFO"
          ./server/conformance-server --policies "$tc/policies.json" --http-port 0 --grpc-port 0 > "$PORT_FIFO" 2>/dev/null &
          SERVER_PID=$!

          # Read exactly two lines (blocks until server writes them)
          HTTP_PORT=""; GRPC_PORT=""
          while IFS= read -r line; do
            case "$line" in
              HTTP_PORT=*) HTTP_PORT="${line#HTTP_PORT=}" ;;
              GRPC_PORT=*) GRPC_PORT="${line#GRPC_PORT=}" ;;
            esac
            if [ -n "$HTTP_PORT" ] && [ -n "$GRPC_PORT" ]; then break; fi
          done < "$PORT_FIFO"
          rm -f "$PORT_FIFO"

          if [ -z "$HTTP_PORT" ]; then
            echo "  ERROR $name (server failed to start)"
            kill $SERVER_PID 2>/dev/null; wait $SERVER_PID 2>/dev/null
            ERRORS=$((ERRORS + 1))
            continue
          fi

          # Determine provider address
          if [ "{{.PROVIDER_FLAG}}" = "--grpc" ]; then
            PROVIDER_ADDR="localhost:$GRPC_PORT"
          else
            PROVIDER_ADDR="http://localhost:$HTTP_PORT/v1/policy/sync"
          fi

          out_ok=true; stats_ok=true
          runner_error=false

          if [ -f "$tc/input.json" ]; then
            # ── Simple mode: single input/output ──
            case "$name" in
              logs_*)    signal=log ;;
              metrics_*) signal=metric ;;
              traces_*)  signal=trace ;;
              *)         signal=$(jq -r "$detect_signal" "$tc/input.json") ;;
            esac

            ./{{.RUNNER}} \
              {{.PROVIDER_FLAG}} "$PROVIDER_ADDR" \
              --input "$tc/input.json" \
              --output "$tc/output_{{.LANG}}_http.json" \
              --signal "$signal" 2>/dev/null
            RUNNER_EXIT=$?

            if [ $RUNNER_EXIT -ne 0 ]; then
              runner_error=true
            else
              # Fetch stats from server
              curl -s "http://localhost:$HTTP_PORT/stats" > "$tc/stats_{{.LANG}}_http.json" 2>/dev/null

              if ! diff <(jq -S "$normalize" "$tc/expected.json") \
                        <(jq -S "$normalize" "$tc/output_{{.LANG}}_http.json") > /dev/null 2>&1; then
                out_ok=false
              fi
              if ! diff <(jq -S "$normalize_http_stats" "$tc/expected_stats.json") \
                        <(jq -S . "$tc/stats_{{.LANG}}_http.json") > /dev/null 2>&1; then
                stats_ok=false
              fi
            fi
          else
            # ── Compound mode: multiple input_N/expected_N pairs ──
            for input_file in $(ls "$tc"/input_*.json 2>/dev/null | sort -t_ -k2 -n); do
              n=$(basename "$input_file" | sed 's/input_\(.*\)\.json/\1/')
              expected_file="$tc/expected_${n}.json"
              output_file="$tc/output_${n}_{{.LANG}}_http.json"
              signal=$(jq -r "$detect_signal" "$input_file")
              if [ "$signal" = "unknown" ]; then
                echo "  SKIP  $name/input_${n}.json (unknown signal)"; continue
              fi

              ./{{.RUNNER}} \
                {{.PROVIDER_FLAG}} "$PROVIDER_ADDR" \
                --input "$input_file" \
                --output "$output_file" \
                --signal "$signal" 2>/dev/null
              RUNNER_EXIT=$?

              if [ $RUNNER_EXIT -ne 0 ]; then
                runner_error=true; break
              fi

              if [ -f "$expected_file" ]; then
                if ! diff <(jq -S "$normalize" "$expected_file") \
                          <(jq -S "$normalize" "$output_file") > /dev/null 2>&1; then
                  out_ok=false
                fi
              fi
            done

            if ! $runner_error; then
              # Fetch accumulated stats from server (single fetch after all batches)
              curl -s "http://localhost:$HTTP_PORT/stats" > "$tc/stats_{{.LANG}}_http.json" 2>/dev/null
              if ! diff <(jq -S "$normalize_http_stats" "$tc/expected_stats.json") \
                        <(jq -S . "$tc/stats_{{.LANG}}_http.json") > /dev/null 2>&1; then
                stats_ok=false
              fi
            fi
          fi

          # Shutdown server
          curl -s "http://localhost:$HTTP_PORT/shutdown" > /dev/null 2>&1
          wait $SERVER_PID 2>/dev/null

          if $runner_error; then
            echo "  ERROR $name (runner exited $RUNNER_EXIT)"
            ERRORS=$((ERRORS + 1))
          elif $out_ok && $stats_ok; then
            echo "  PASS  $name"
            PASS=$((PASS + 1))
          else
            echo "  FAIL  $name"
            if ! $out_ok; then
              if [ -f "$tc/input.json" ]; then
                echo "    output diff:"
                diff <(jq -S "$normalize" "$tc/expected.json") \
                     <(jq -S "$normalize" "$tc/output_{{.LANG}}_http.json") || true
              else
                for input_file in $(ls "$tc"/input_*.json 2>/dev/null | sort -t_ -k2 -n); do
                  n=$(basename "$input_file" | sed 's/input_\(.*\)\.json/\1/')
                  expected_file="$tc/expected_${n}.json"
                  output_file="$tc/output_${n}_{{.LANG}}_http.json"
                  if [ -f "$expected_file" ] && ! diff <(jq -S "$normalize" "$expected_file") \
                        <(jq -S "$normalize" "$output_file") > /dev/null 2>&1; then
                    echo "    output diff (batch $n):"
                    diff <(jq -S "$normalize" "$expected_file") \
                         <(jq -S "$normalize" "$output_file") || true
                  fi
                done
              fi
            fi
            if ! $stats_ok; then
              echo "    stats diff:"
              diff <(jq -S "$normalize_http_stats" "$tc/expected_stats.json") \
                   <(jq -S . "$tc/stats_{{.LANG}}_http.json") || true
            fi
            FAIL=$((FAIL + 1))
          fi
        done
        echo ""
        echo "{{.LANG}} ({{.PROVIDER_FLAG}}): $PASS passed, $FAIL failed, $ERRORS errors"
        [ "$FAIL" -eq 0 ] && [ "$ERRORS" -eq 0 ]

  # ── Benchmarks ──────────────────────────────────────────────
  bench:
    desc: Benchmark all runners against each test case
    aliases: [bch]
    deps: [build]
    cmds:
      - |
        for tc in testcases/*/; do
          name=$(basename "$tc")
          case "$name" in
            logs_*)    signal=log ;;
            metrics_*) signal=metric ;;
            traces_*)  signal=trace ;;
            *)         continue ;;
          esac
          echo "── $name ──"
          hyperfine --warmup 2 -N \
            -n go  "./runners/go/runner-go --policies $tc/policies.json --input $tc/input.json --output /dev/null --stats /dev/null --signal $signal" \
            -n rs   "./runners/rs/target/release/runner-rs --policies $tc/policies.json --input $tc/input.json --output /dev/null --stats /dev/null --signal $signal" \
            -n zig  "./runners/zig/zig-out/bin/runner-zig --policies $tc/policies.json --input $tc/input.json --output /dev/null --stats /dev/null --signal $signal"
          echo ""
        done

  # ── Repeat a single test N times ────────────────────────────
  test:repeat:
    desc: "Run a single test case N times (e.g. task test:repeat TC=traces_sampling_50pct N=100 R=go)"
    aliases: [tr]
    vars:
      TC: '{{.TC | default ""}}'
      R: '{{.R | default "all"}}'
      N: '{{.N | default "10"}}'
    cmds:
      - |
        NAME="{{.TC}}"
        LANGS="{{.R}}"
        COUNT="{{.N}}"
        if [ -z "$NAME" ]; then
          echo "usage: task test:repeat TC=<testcase> [R=<go|rs|zig|all>] [N=<count>]"
          exit 1
        fi
        tc="testcases/$NAME/"
        if [ ! -d "$tc" ]; then
          echo "ERROR: $tc not found"; exit 1
        fi
        if [ "$LANGS" = "all" ]; then
          LANGS="go rs zig"
        fi

        normalize='def enums: {"SPAN_KIND_INTERNAL":1,"SPAN_KIND_SERVER":2,"SPAN_KIND_CLIENT":3,"SPAN_KIND_PRODUCER":4,"SPAN_KIND_CONSUMER":5,"STATUS_CODE_OK":1,"STATUS_CODE_ERROR":2,"AGGREGATION_TEMPORALITY_DELTA":1,"AGGREGATION_TEMPORALITY_CUMULATIVE":2,"SEVERITY_NUMBER_TRACE":1,"SEVERITY_NUMBER_TRACE2":2,"SEVERITY_NUMBER_TRACE3":3,"SEVERITY_NUMBER_TRACE4":4,"SEVERITY_NUMBER_DEBUG":5,"SEVERITY_NUMBER_DEBUG2":6,"SEVERITY_NUMBER_DEBUG3":7,"SEVERITY_NUMBER_DEBUG4":8,"SEVERITY_NUMBER_INFO":9,"SEVERITY_NUMBER_INFO2":10,"SEVERITY_NUMBER_INFO3":11,"SEVERITY_NUMBER_INFO4":12,"SEVERITY_NUMBER_WARN":13,"SEVERITY_NUMBER_WARN2":14,"SEVERITY_NUMBER_WARN3":15,"SEVERITY_NUMBER_WARN4":16,"SEVERITY_NUMBER_ERROR":17,"SEVERITY_NUMBER_ERROR2":18,"SEVERITY_NUMBER_ERROR3":19,"SEVERITY_NUMBER_ERROR4":20,"SEVERITY_NUMBER_FATAL":21,"SEVERITY_NUMBER_FATAL2":22,"SEVERITY_NUMBER_FATAL3":23,"SEVERITY_NUMBER_FATAL4":24}; walk(if type == "object" then with_entries(select(.value != null and .value != [] and .value != "" and .value != 0 and .value != {} and .value != false and (.value | IN("SEVERITY_NUMBER_UNSPECIFIED","STATUS_CODE_UNSET","SPAN_KIND_UNSPECIFIED","AGGREGATION_TEMPORALITY_UNSPECIFIED") | not)) | if .value | type == "string" then .value = (enums[.value] // .value) else . end) elif type == "string" and test("^[0-9]+$") then tonumber elif type == "number" and (. | floor) == . then (. | floor) else . end)'
        merge_stats='[.[].policies[]] | group_by(.policy_id) | map({policy_id: .[0].policy_id, hits: (map(.hits) | add), misses: (map(.misses // 0) | add)}) | map(if .misses == 0 then del(.misses) else . end) | sort_by(.policy_id) | {policies: .}'
        detect_signal='if .resourceLogs then "log" elif .resourceMetrics then "metric" elif .resourceSpans then "trace" else "unknown" end'

        ANY_FAIL=false
        for _LANG in $LANGS; do
          case "$_LANG" in
            go)  RUNNER=runners/go/runner-go ;;
            rs)  RUNNER=runners/rs/target/release/runner-rs ;;
            zig) RUNNER=runners/zig/zig-out/bin/runner-zig ;;
            *)   echo "ERROR: unknown lang $_LANG (use go, rs, zig, all)"; exit 1 ;;
          esac

          PASS=0; FAIL=0
          for i in $(seq 1 "$COUNT"); do
            if [ -f "$tc/input.json" ]; then
              # ── Simple mode ──
              case "$NAME" in
                logs_*)    signal=log ;;
                metrics_*) signal=metric ;;
                traces_*)  signal=trace ;;
                *)         signal=$(jq -r "$detect_signal" "$tc/input.json") ;;
              esac
              ./$RUNNER \
                --policies "$tc/policies.json" \
                --input "$tc/input.json" \
                --output "$tc/output_${_LANG}.json" \
                --stats "$tc/stats_${_LANG}.json" \
                --signal "$signal"
              ok=true
              if ! diff <(jq -S "$normalize" "$tc/expected.json") \
                        <(jq -S "$normalize" "$tc/output_${_LANG}.json") > /dev/null 2>&1; then
                ok=false
              fi
              if ! diff <(jq -S . "$tc/expected_stats.json") \
                        <(jq -S . "$tc/stats_${_LANG}.json") > /dev/null 2>&1; then
                ok=false
              fi
            else
              # ── Compound mode ──
              ok=true
              STATS_FILES=""
              for input_file in $(ls "$tc"/input_*.json 2>/dev/null | sort -t_ -k2 -n); do
                n=$(basename "$input_file" | sed 's/input_\(.*\)\.json/\1/')
                expected_file="$tc/expected_${n}.json"
                output_file="$tc/output_${n}_${_LANG}.json"
                stats_file="$tc/stats_${n}_${_LANG}.json"
                signal=$(jq -r "$detect_signal" "$input_file")
                ./$RUNNER \
                  --policies "$tc/policies.json" \
                  --input "$input_file" \
                  --output "$output_file" \
                  --stats "$stats_file" \
                  --signal "$signal"
                if [ -f "$expected_file" ]; then
                  if ! diff <(jq -S "$normalize" "$expected_file") \
                            <(jq -S "$normalize" "$output_file") > /dev/null 2>&1; then
                    ok=false
                  fi
                fi
                STATS_FILES="$STATS_FILES $stats_file"
              done
              if [ -n "$STATS_FILES" ]; then
                jq -s "$merge_stats" $STATS_FILES > "$tc/stats_${_LANG}.json"
                if ! diff <(jq -S . "$tc/expected_stats.json") \
                          <(jq -S . "$tc/stats_${_LANG}.json") > /dev/null 2>&1; then
                  ok=false
                fi
              fi
            fi

            if $ok; then
              PASS=$((PASS + 1))
            else
              echo "  FAIL  $_LANG run $i/$COUNT"
              FAIL=$((FAIL + 1))
            fi
          done
          echo "$NAME ($_LANG): $PASS passed, $FAIL failed out of $COUNT runs"
          if [ "$FAIL" -gt 0 ]; then ANY_FAIL=true; fi
        done
        ! $ANY_FAIL

  # ── Utilities ──────────────────────────────────────────────
  clean:
    desc: Clean build artifacts and outputs
    aliases: [c]
    cmds:
      - rm -f runners/go/runner-go
      - rm -f server/conformance-server
      - rm -f testcases/*/output_*.json
      - rm -f testcases/*/stats_*.json
      - cd runners/rs && cargo clean
      - cd runners/zig && rm -rf zig-out .zig-cache

  # ── Implementation tests ────────────────────────────────────
  build:sink:
    desc: Build sink server for implementation tests
    dir: implementations/sink
    cmds:
      - go build -o sink-server .

  test:impl:collector:
    desc: Run implementation conformance tests for tero-collector-distro
    aliases: [tic]
    deps: [build:sink]
    cmds:
      - task: conformance:impl
        vars:
          IMPL: tero-collector-distro
          IMPL_NAME: collector
          IMPL_BIN: implementations/tero-collector-distro/tero-collector
          IMPL_START_CMD: "--config"
          CONFIG_TEMPLATE: implementations/tero-collector-distro/config.template.yaml
          CONFIG_EXT: yaml

  test:impl:edge:
    desc: Run implementation conformance tests for edge
    aliases: [tie]
    deps: [build:sink]
    cmds:
      - task: conformance:impl
        vars:
          IMPL: edge
          IMPL_NAME: edge
          IMPL_BIN: implementations/edge/edge
          IMPL_START_CMD: ""
          CONFIG_TEMPLATE: implementations/edge/config.template.json
          CONFIG_EXT: json

  test:impl:
    desc: Run implementation conformance tests for all implementations
    aliases: [ti]
    cmds:
      - task: test:impl:collector
      - task: test:impl:edge

  conformance:impl:
    desc: Run test cases against a single implementation
    internal: true
    cmds:
      - |
        set +e

        IMPL_BIN="{{.IMPL_BIN}}"
        if [ ! -x "$IMPL_BIN" ]; then
          echo "SKIP: $IMPL_BIN not found (place the binary and chmod +x)"
          exit 0
        fi

        # Normalize: strip proto defaults (0, "", [], {}, false, null, unspecified enums)
        # and coerce string-encoded numbers. Same filter as the runner conformance tasks.
        normalize='def enums: {"SPAN_KIND_INTERNAL":1,"SPAN_KIND_SERVER":2,"SPAN_KIND_CLIENT":3,"SPAN_KIND_PRODUCER":4,"SPAN_KIND_CONSUMER":5,"STATUS_CODE_OK":1,"STATUS_CODE_ERROR":2,"AGGREGATION_TEMPORALITY_DELTA":1,"AGGREGATION_TEMPORALITY_CUMULATIVE":2,"SEVERITY_NUMBER_TRACE":1,"SEVERITY_NUMBER_TRACE2":2,"SEVERITY_NUMBER_TRACE3":3,"SEVERITY_NUMBER_TRACE4":4,"SEVERITY_NUMBER_DEBUG":5,"SEVERITY_NUMBER_DEBUG2":6,"SEVERITY_NUMBER_DEBUG3":7,"SEVERITY_NUMBER_DEBUG4":8,"SEVERITY_NUMBER_INFO":9,"SEVERITY_NUMBER_INFO2":10,"SEVERITY_NUMBER_INFO3":11,"SEVERITY_NUMBER_INFO4":12,"SEVERITY_NUMBER_WARN":13,"SEVERITY_NUMBER_WARN2":14,"SEVERITY_NUMBER_WARN3":15,"SEVERITY_NUMBER_WARN4":16,"SEVERITY_NUMBER_ERROR":17,"SEVERITY_NUMBER_ERROR2":18,"SEVERITY_NUMBER_ERROR3":19,"SEVERITY_NUMBER_ERROR4":20,"SEVERITY_NUMBER_FATAL":21,"SEVERITY_NUMBER_FATAL2":22,"SEVERITY_NUMBER_FATAL3":23,"SEVERITY_NUMBER_FATAL4":24}; walk(if type == "object" then with_entries(select(.value != null and .value != [] and .value != "" and .value != 0 and .value != {} and .value != false and (.value | IN("SEVERITY_NUMBER_UNSPECIFIED","STATUS_CODE_UNSET","SPAN_KIND_UNSPECIFIED","AGGREGATION_TEMPORALITY_UNSPECIFIED") | not)) | if .value | type == "string" then .value = (enums[.value] // .value) else . end) elif type == "string" and test("^[0-9]+$") then tonumber elif type == "number" and (. | floor) == . then (. | floor) else . end)'

        IMPL_PID=""; SINK_PID=""
        kill_servers() {
          [ -n "$IMPL_PID" ] && kill -9 "$IMPL_PID" 2>/dev/null; IMPL_PID=""
          [ -n "$SINK_PID" ] && kill -9 "$SINK_PID" 2>/dev/null; SINK_PID=""
        }
        trap kill_servers EXIT

        TC_FILTER="{{.TC}}"
        PASS=0; FAIL=0; SKIP=0; ERRORS=0

        for tc in testcases/*/; do
          name=$(basename "$tc")

          # If TC filter is set, only run that test case
          if [ -n "$TC_FILTER" ] && [ "$name" != "$TC_FILTER" ]; then
            continue
          fi

          # ── Determine signal and endpoint ──
          if [ -f "$tc/input.json" ]; then
            case "$name" in
              logs_*)    ENDPOINT="/v1/logs" ;;
              metrics_*) ENDPOINT="/v1/metrics" ;;
              traces_*)  ENDPOINT="/v1/traces" ;;
              *)         SKIP=$((SKIP + 1)); continue ;;
            esac
          else
            SKIP=$((SKIP + 1))
            continue
          fi

          # ── Pick a free port for the receiver ──
          RECEIVER_PORT=$(python3 -c "import socket; s=socket.socket(); s.bind(('',0)); print(s.getsockname()[1]); s.close()")

          # ── Start sink server (FIFO handshake) ──
          SINK_FIFO=$(mktemp -u)
          mkfifo "$SINK_FIFO"
          ./implementations/sink/sink-server --port 0 > "$SINK_FIFO" 2>/dev/null &
          SINK_PID=$!

          SINK_PORT=""
          while IFS= read -r line; do
            case "$line" in
              SINK_PORT=*) SINK_PORT="${line#SINK_PORT=}" ;;
            esac
            if [ -n "$SINK_PORT" ]; then break; fi
          done < "$SINK_FIFO"
          rm -f "$SINK_FIFO"

          if [ -z "$SINK_PORT" ]; then
            echo "  ERROR $name (sink failed to start)"
            kill_servers
            ERRORS=$((ERRORS + 1))
            continue
          fi

          # ── Generate runtime config ──
          POLICIES_PATH="$(pwd)/$tc/policies.json"
          export RECEIVER_PORT SINK_PORT POLICIES_PATH
          CONFIG_FILE=$(mktemp).{{.CONFIG_EXT}}
          envsubst < "{{.CONFIG_TEMPLATE}}" > "$CONFIG_FILE"

          # ── Start implementation ──
          if [ -n "{{.IMPL_START_CMD}}" ]; then
            ./$IMPL_BIN {{.IMPL_START_CMD}} "$CONFIG_FILE" > /dev/null 2>&1 &
          else
            ./$IMPL_BIN "$CONFIG_FILE" > /dev/null 2>&1 &
          fi
          IMPL_PID=$!

          # ── Wait for readiness (poll receiver) ──
          READY=false
          for i in $(seq 1 50); do
            if curl -sf -o /dev/null -X POST "http://localhost:$RECEIVER_PORT$ENDPOINT" \
                 -H "Content-Type: application/json" -d '{}' 2>/dev/null; then
              READY=true
              break
            fi
            sleep 0.1
          done

          # Reset sink after readiness probe (may have forwarded empty data)
          curl -s "http://localhost:$SINK_PORT/reset" > /dev/null 2>&1

          if ! $READY; then
            echo "  ERROR $name (implementation not ready after 5s)"
            kill_servers
            rm -f "$CONFIG_FILE"
            ERRORS=$((ERRORS + 1))
            continue
          fi

          # ── Send input data ──
          curl -s -X POST "http://localhost:$RECEIVER_PORT$ENDPOINT" \
            -H "Content-Type: application/json" \
            -d @"$tc/input.json" > /dev/null 2>&1

          # ── Wait for data to arrive at sink (2s timeout for drop-all cases) ──
          for i in $(seq 1 20); do
            if curl -sf -o /dev/null "http://localhost:$SINK_PORT/has-data" 2>/dev/null; then
              break
            fi
            sleep 0.1
          done
          sleep 0.1
          curl -s "http://localhost:$SINK_PORT/output" > "$tc/output_{{.IMPL_NAME}}.json" 2>/dev/null

          # ── Shutdown (force kill, no graceful wait) ──
          kill_servers
          rm -f "$CONFIG_FILE"

          # ── Compare output ──
          out_ok=true
          if ! diff <(jq -S "$normalize" "$tc/expected.json") \
                    <(jq -S "$normalize" "$tc/output_{{.IMPL_NAME}}.json") > /dev/null 2>&1; then
            out_ok=false
          fi

          if $out_ok; then
            echo "  PASS  $name"
            PASS=$((PASS + 1))
          else
            echo "  FAIL  $name"
            echo "    output diff:"
            diff <(jq -S "$normalize" "$tc/expected.json") \
                 <(jq -S "$normalize" "$tc/output_{{.IMPL_NAME}}.json") || true
            FAIL=$((FAIL + 1))
          fi
        done
        echo ""
        echo "{{.IMPL_NAME}}: $PASS passed, $FAIL failed, $ERRORS errors, $SKIP skipped"
        [ "$FAIL" -eq 0 ] && [ "$ERRORS" -eq 0 ]

  ci:setup:
    desc: Install CI dependencies (hyperscan/vectorscan)
    cmds:
      - |
        if pkg-config --exists libhs 2>/dev/null; then
          echo "libhs already installed"
          exit 0
        fi
        OS=$(uname -s)
        if [ "$OS" = "Darwin" ]; then
          brew install vectorscan
        else
          sudo apt-get update && sudo apt-get install -y libhyperscan-dev
        fi
